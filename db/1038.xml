<?xml version="1.0" encoding="ISO-8859-1"?>
<?xml-stylesheet type="text/xsl" href="helma.xsl"?>
<xmlroot xmlns:hop="http://www.helma.org/docs/guide/features/database">
  <hopobject id="1038" name="H.264-based 2D-3D conversion" prototype="Page" created="1270639091633" lastModified="1452791149119">
  <hop:parent idref="20" prototyperef="Page"/>
    <is_xhtml type="boolean">true</is_xhtml>
    <http_remotehost>127.0.0.1</http_remotehost>
    <pname>An H.264-based depth generation for 2D to 3D conversion</pname>
    <registrant>zhouruili.myopenid.com</registrant>
    <http_language>zh-cn,zh;q=0.5</http_language>
    <uri>H.264-based 2D-3D conversion</uri>
    <http_browser>Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.9) Gecko/20100315 Firefox/3.5.9</http_browser>
    <time type="date">07.04.2010 11:20:55 UTC</time>
    <updatetime type="date">07.04.2010 11:18:11 UTC</updatetime>
    <hopsession>127.0.0.58.60.1.jivinx2t89ia</hopsession>
    <body>With the development of 3DTV, the conversion of existing 2D videos to 3D videos has become one of the most important component of 3D content production. One of the key steps in 2D to 3D conversion is how to generate a dense depth map.In this project, a novel depth extraction method is proposed for 2D to 3D conversion.
As H.264 has been chosen as one of the platforms for 3DTV applications, it is a good choice for us to generate the depth map based on H.264. In the project,motion information based on H.264 is used to derive the displacement of objects over two consecutive frames.Comparing with other algorithms, it is readily available in the form of motion vectors(MVs) at the receiver-end at no additional computational cost .What is more,there is no need for the sender to send the depth information, which makes the system real-time.
The left and right view images can be generated from the original 2D video and its Depth Image.With some pre-processing and hole-filling procedures, we finally get the left and right eye view for 3D display.
The performance of generated stereoscopic video was evaluated in a subjective manner, by surveying participants after watching the stereoscopic video.
Some techologies like OpenCV(an Open Computer Vision Library), Angstrom Operating System, GTK+ for the User Interface and JM(an open source lirbary)are used in the project. Meanwhile, our operating System and main algorithm are run respectively on Arm and Dsp which use the Omap 3530 beagleboard as the platform.</body>
    <pseudoparent idref="20" prototyperef="Page"/>
    <rssfeed></rssfeed>
    <pvcount type="float">3559.0</pvcount>
    <homepage></homepage>
    <render_skin>project</render_skin>
    <edit_skin>edit_project</edit_skin>
    <http_referer>http://beagleboard.org/project/H.264-based%202D-3D%20conversion/edit</http_referer>
    <http_host>beagleboard.org</http_host>
    <errmsg></errmsg>
    <shortdesc>As H.264 has been chosen as one of the platforms for 3DTV applications, it is a good choice for us to generate the depth map based on H.264. In the project,motion information based on H.264 is used to derive the displacement of objects over two consecutive frames.Comparing with other algorithms, it is readily available in the form of motion vectors(MVs) at the receiver-end at no additional computational cost .What is more,there is no need for the sender to send the depth information, which makes the system real-time.</shortdesc>
    <user>zhouruili.myopenid.com</user>
  </hopobject>
</xmlroot>
