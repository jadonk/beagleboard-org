<?xml version="1.0" encoding="ISO-8859-1"?>
<?xml-stylesheet type="text/xsl" href="helma.xsl"?>
<xmlroot xmlns:hop="http://www.helma.org/docs/guide/features/database">
  <hopobject id="885" name="Beagle-Eye" prototype="Page" created="1259355290029" lastModified="1421955349062">
  <hop:parent idref="20" prototyperef="Page"/>
    <is_xhtml type="boolean">true</is_xhtml>
    <http_remotehost>127.0.0.1</http_remotehost>
    <pname>Beagle Eye</pname>
    <registrant>leatherbrain.myopenid.com</registrant>
    <http_language>en-gb,en;q=0.5</http_language>
    <uri>Beagle-Eye</uri>
    <http_browser>Mozilla/5.0 (X11; U; Linux i686; en-GB; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7</http_browser>
    <time type="date">14.01.2010 22:45:00 UTC</time>
    <updatetime type="date">27.11.2009 20:54:50 UTC</updatetime>
    <hopsession>127.0.0.137.222.102.1rxs5eyteeald</hopsession>
    <body>Hardware:

A pair of calibrated USB cameras, mounted on the user&apos;s shoulders, such that the combined field of view covers at least 180 degrees.

One or more linear actuators connected through RS-232, situated on one of the user&apos;s limbs.

Stereo headphones.

USB GPS Dongle. 

Description:

Low frame rate real-time video is used to guide the user towards a specified destination.

The GPS provides coarse location.

The stereo camera setup provides a wide field of view, along with coarse depth information.

Map information, combined with real time video is used to esimate location and orientation more accurately.

Simple object recognition techniques are employed to recognize parts of the environment.

The audio setup and the actuator(s) are used either in tandem or interchangeably to guide the user. This can be customized as required. Some possibilities include:
- A short periodic 3D sound generated to indicate the direction in which the user is to walk.
- The user is alerted about approaching obstacles by firing the actuator at a frequency inversely proportional to the distance to the obstacle. This distance can be computed using depth information computed from pairs of images.
- Information about the environment, such as &quot;Pedestrian Crossing in 20m&quot; can be relayed through audio. 

Possible Enhancements:

More comprehensive localization techniques, such as SLAM, can be used to improve the accuracy of the system. This will also open doors to indoor navigation, where the GPS fails.

Detection, segmentation and recognition of text (such as signboards and street names) in the environment will ensure less errors in navigation. 

Expected Results:

A navigation tool for the visually challenged, using audio and linear actuators to communicate with the user.</body>
    <pseudoparent idref="20" prototyperef="Page"/>
    <rssfeed></rssfeed>
    <pvcount type="float">1570.0</pvcount>
    <homepage>www.cs.bris.ac.uk/~sundaram</homepage>
    <render_skin>project</render_skin>
    <edit_skin>edit_project</edit_skin>
    <http_referer>http://beagleboard.org/project/Beagle-Eye/edit</http_referer>
    <http_host>beagleboard.org</http_host>
    <errmsg></errmsg>
    <shortdesc>A beagle-eyed guide for the visually challenged</shortdesc>
    <user>leatherbrain.myopenid.com</user>
  </hopobject>
</xmlroot>
